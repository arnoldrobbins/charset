\input texinfo   @c -*-texinfo-*-
@c vim: filetype=texinfo tabstop=4 shiftwidth=4
@c %**start of header (This is for running Texinfo on a region.)
@setfilename charset.info
@settitle Efficient Searching of Large Character Sets --- Take Two
@c %**end of header (This is for running Texinfo on a region.)

@c Change how xref titles are quoted.
@dquotexrefs
@ifclear FORPRINT
@pdflinkcolor
@urllinkcolor
@hideurls
@end ifclear


@c The following information should be updated here only!
@c This sets the edition of the document.

@c These apply across the board.
@set UPDATE-MONTH November, 2024
@set EDITION 0.1

@set TITLE Efficient Searching of Large Character Sets --- Take Two
@set SHORTTITLE Searching Character Sets

@iftex
@set DOCUMENT book
@set CHAPTER chapter
@set APPENDIX appendix
@set SECTION section
@set SUBSECTION subsection
@end iftex
@ifhtml
@set DOCUMENT Web page
@set CHAPTER chapter
@set APPENDIX appendix
@set SECTION section
@set SUBSECTION subsection
@end ifhtml
@ifinfo
@set DOCUMENT Info file
@set CHAPTER major node
@set APPENDIX major node
@set SECTION minor node
@set SUBSECTION node
@end ifinfo
@ifdocbook
@set DOCUMENT book
@set CHAPTER chapter
@set APPENDIX appendix
@set SECTION section
@set SUBSECTION subsection
@end ifdocbook

@c some special symbols
@ifnottex
@macro ii{text}
@i{\text\}
@end macro
@end ifnottex

@c Uncomment this if you want the metafont logo.
@ignore
@ifnottex
@macro MF{}
@sc{METAFONT}
@end macro
@end ifnottex
@end ignore

@c merge the function and variable indexes into the concept index
@c do so without the code font, and in the index entries do the
@c font management ourselves.  Also merge in the chunk definition
@c and reference entries, which jrweave creates for us.
@ifnothtml
@synindex fn cp
@synindex vr cp
@synindex cd cp
@synindex cr cp
@end ifnothtml

@c If "finalout" is commented out, the printed output will show
@c black boxes that mark lines that are too long.  Thus, it is
@c unwise to comment it out when running a master in case there are
@c overfulls which are deemed okay.

@iftex
@c @finalout
@end iftex

@copying
@docbook
<para>Published by:</para>

<literallayout class="normal">Arnold David Robbins
P.O. Box 354
Nof Ayalon 9978500
ISRAEL
Email: <email>arnold@@skeeve.com</email>
URL: <ulink url="https://www.skeeve.com/">https://www.skeeve.com/</ulink></literallayout>

<literallayout class="normal">Copyright &copy; 2024
Arnold David Robbins
All Rights Reserved.</literallayout>
@end docbook

@ifnotdocbook
Copyright @copyright{} 2024 @*
Arnold David Robbins @*
All Rights Reserved.
@end ifnotdocbook
@sp 1
The charset program is copyright
@copyright{} 2024 by Arnold David Robbins.
@c It is published under the conditions of a BSD license yet to be determined.
Not for publication, yet.
@sp 2
This is Edition @value{EDITION} of @cite{@value{TITLE}}.
@end copying

@c Uncomment this for the release.  Leaving it off saves paper
@c during editing and review.
@c @setchapternewpage odd

@c Uncomment this if it's ever printed as a real book(let).
@c @shorttitlepage @value{SHORTTITLE}

@titlepage
@title @value{TITLE}
@subtitle @value{UPDATE-MONTH}
@author Arnold David Robbins

@ifnotdocbook
@c Include the Distribution inside the titlepage environment so
@c that headings are turned off.  Headings on and off do not work.

@page
@vskip 0pt plus 1filll
Published by:
@sp 1
Arnold David Robbins @*
P.O. Box 354 @*
Nof Ayalon 9978500 @*
ISRAEL @*
Email: @EMAIL{arnold@@skeeve.com,arnold AT skeeve.com} @*
URL: @url{https://www.skeeve.com/} @*

@insertcopying
@end ifnotdocbook
@end titlepage

@set DRAFT

@iftex
@headings off
@evenheading @thispage @| @value{DRAFT} @| @strong{@value{SHORTTITLE}}
@oddheading  @strong{@thischapter} @| @value{DRAFT} @| @thispage
@end iftex

@ifnottex
@ifnotdocbook
@ifnotxml
@node Top
@top General Introduction
@c Preface node should come right after the Top
@c node, in `unnumbered' sections, then the introductory chapter.
@c Licensing nodes are appendices, they're not central to TexiWebJr.

This file documents @code{charset}, a set of functions that accept
a wide character value and search a defined set of characters to
see if the value is in the set.  It is intended for use within
a regular expression matching library.

@insertcopying
@end ifnotxml
@end ifnotdocbook
@end ifnottex

@menu
@detailmenu
@end detailmenu
@end menu

@c @summarycontents
@contents

@c Add these to the menu if they ever get included.
@c @node Foreword
@c @unnumbered Foreword

@node Preface
@unnumbered Preface

This @value{DOCUMENT} documents @code{charset}, a set of functions that accept
a wide character value and search a defined set of characters to
see if the value is in the set.  It is intended for use within
a regular expression matching library.

@menu
* Audience::                    Who should read this @value{DOCUMENT}.
* Conventions::                 Typographical conventions.
* Acknowledgements::            Acknowledgements.
@end menu

@node Audience
@unnumberedsec Intended Audience

If you're interested in one way to search bracket expressions for
a matching character value when using very large character sets
(such as Unicode), you should read this @value{DOCUMENT}.

@node Conventions
@unnumberedsec Typographical Conventions

@c Copied mostly verbatim from the gawk manual.

@cindex Texinfo document formatting language
This @value{DOCUMENT} is written in an enhanced version of
@uref{https://www.gnu.org/software/texinfo/, Texinfo},
the GNU documentation formatting language.
A single Texinfo source file is used to produce both the printed and online
versions of a program's documentation.
@ifnotinfo
Because of this, the typographical conventions
are slightly different than in other books you may have read.
@end ifnotinfo

Examples you would type at the command-line are preceded by the common
shell primary and secondary prompts, @samp{$} and @samp{>}.  Input that
you type is shown @kbd{like this}.  Output from the command is preceded
by the glyph ``@print{}''.  This typically represents the command's
standard output.  Error messages, and other output on the command's
standard error, are preceded by the glyph ``@error{}''.  For example:

@example
$ @kbd{echo hi on stdout}
@print{} hi on stdout
$ @kbd{echo hello on stderr 1>&2}
@error{} hello on stderr
@end example

@ifnotinfo
In the text, command names appear in @code{this font}, while code segments
appear in the same font and quoted, @samp{like this}.  Options look
like this: @option{-f}.  Some things are emphasized @emph{like this},
and if a point needs to be made strongly, it is done @strong{like this}.
The first occurrence of a new term is usually its @dfn{definition} and
appears in the same font as the previous occurrence of ``definition''
in this sentence.  Finally, file names are indicated like this:
@file{/path/to/our/file}.
@end ifnotinfo

@node Acknowledgements
@unnumberedsec Acknowledgements

Thanks to Mike Haertel for his feedback, and for giving me the
opportunity to write this bit of code.

@node Introduction
@chapter Introduction

In the fall of 2023, Mike Haertel started writing a new regular expression library,
@uref{https://github.com/mikehaertel/minrx, MinRX},
with the aim of eventually replacing the matchers in use by GNU Awk
(@command{gawk}).  The initial version is in C++; it will eventually be translated
to C for portability. As of August 2024, it's working fully.

As part of the discussion between Mike and myself, I offered a rough draft of a
data structure to use for quickly seeing if a character matches a @dfn{bracket expression},
which is a construct used within regular expressions to represent sets of different
kinds of characters to be matched.
The ideas for this data structure and how to use it had been bouncing around in
my head for some time.

I initially wrote a library---setsearch---that parsed bracket expressions,
built the data structure, and then used it. It's still available at
@uref{https://github.com/arnoldrobbins/setsearch}.  However, further discussion
with Mike revealed that what he really needed was just a data structure for
storing sets of characters and testing an input character against the set;
he preferred to do his own parsing of the bracket expression, and add characters
to the set as needed.

As a result, I designed a new API that still uses the same underlying
data structures. Thus, this @value{DOCUMENT} presents the design and
implementation of a sublibrary (so to speak) for dealing with character
sets.
Almost all of the original setsearch code and literate
documentation are reused here, but in a different way.
In particular, the code for parsing a bracket expression will
come in handy for the test program.

The machine-readable files are available from GitHub. The steps
necessary to get them are:

@example
git clone https://github.com/arnoldrobbins/charset
cd charset
vim jrweave jrtangle    # or emacs :-). Set the path to gawk
make
@end example

@noindent
In order to format the document,
you will need to have @TeX{} and Texinfo installed,
including @command{texi2pdf}.  Or you can ask me for
a PDF, if necessary.

@node Problem Statement
@chapter Problem Statement

Let's first define the problem.  We want a way to represent a defined set of
characters, and then test if any given character is in the set or not.

In the Good Old Days@registeredsymbol{}, with 7-bit ASCII, you could do this
using a bitmap of 128 bits, which would take up on four 32-bit words.
Even for eight bit character sets, you'd only need eight 32-bit words.

In Unicode, which has over a million characters, a bit map would be very big.
In particular, it's likely that it would be mostly empty; such sets of characters
may have a few dozen or so characters in them, but not thousands or hundreds of thousands.

Therefore, we need a data structure that is efficient in two dimensions:
time for searching, and space that it occupies. I think the data structure
presented here meets both criteria.

@node The Data Structure
@chapter The Underlying Data Structure

We'll start with the underlying data structure and how
it's searched, and then move on to how it's built
and the API that manages it.

A single item in the set is represented by
a set item:

@<data structures@>=
typedef struct set_item {
	enum set_item_type {
		CTYPE_ITEM,
		RANGE_ITEM,
	} item_type;
	union {
		struct _ctype {
			wctype_t    wtype;
			const char *type_name;
		} c;
		struct _range {
			int32_t start, end;
		} r;
	} u;
} set_item;
#define wtype		u.c.wtype
#define type_name	u.c.type_name
#define start		u.r.start
#define end			u.r.end
@

A @code{set_item} holds one of two things:

@itemize @bullet
@item Information needed for use with the @code{iswctype()} function.
This consists of a value of type @code{wctype_t}, and a pointer to
a string representing the ctype.

@item A range, such as @code{[a-z]}.
Single characters that
aren't contiguous with others are placed in a range where
@code{start} and @code{end} are set to the same value.
@end itemize

The full @code{charset_t} holds a dynamically allocated
array of @code{set_item}s, items needed for building
the set, and what's needed for managing
the memory:

@<data structures@>=
struct _charset {
	bool     complemented;      // For [^...] sets
	bool     no_newlines;       // For dumping
	bool     finalized;         // No more changes possible
	size_t   nchars_inuse;      // Number of characters used
	size_t   nchars_allocated;  // Number of characters allocated
	int32_t  *chars;            // Characters added to the set
	size_t   nelems;            // Number of elements in use
	size_t   allocated;         // Number allocated
	set_item *items;            // Array of items
};
@

We will see how it's built up and used as we go along.

@node API Functions
@chapter API Functions

Here are the functions for the API.

@node Error Codes
@section Error Codes

Almost all of the functions return a success or error value via a
pointer to a plain integer. Here are the error codes:

@<error codes@>=
// error code values:
enum {
	CSET_SUCCESS = 0,		// no problems
	CSET_EBADPTR,		// NULL pointer received
	CSET_EFROZEN,		// Cannot add more characters to the set
	CSET_ECOLLATE,		// Corresponds to REG_ECOLLATE
	CSET_ECTYPE,		// Corresponds to REG_ECTYPE
	CSET_ESPACE,		// Corresponds to REG_ESPACE
	CSET_ERANGE,		// Corresponds to REG_ERANGE
};
@

@node Creating The Charset
@section Creating The Charset

Creating the character set simply
allocates the memory and forces it to zero.
Then we check the flags.

@<API declarations@>=
typedef enum {
	CSET_NO_FLAGS = 0,	// no special cases
	CSET_NO_NEWLINE = 0x01,	// \n not allowed in inverted range or "all chars"
	// other flags may be added if needed
} charset_flags_t;

@<error codes@>
@


@<API functions@>=
/* charset_create --- make a new charset_t and initialize it */

charset_t *
charset_create(charset_flags_t flags, int *errcode)
{
	if (errcode == NULL)
		return NULL;

	charset_t *set = (charset_t *) malloc(sizeof(charset_t));
	if (set == NULL) {
		*errcode = CSET_ESPACE;
		return NULL;
	}

	memset(set, 0, sizeof(charset_t));

	if ((flags & CSET_NO_NEWLINE) != 0)
		set->no_newlines = true;

	*errcode = CSET_SUCCESS;
	return set;
}
@

@<API declarations@>=
charset_t *charset_create(charset_flags_t flags, int *errcode);
@

@node Adding A Character
@section Adding A Character

The @code{charset_t} is intended for matching bracket expressions,
which can have multiple single characters, ranges, and other objects.
The most fundamental object is a single character, for example,
@code{[aeiouy]}.  As the regex engine parses the bracket expression,
it adds characters to the @code{charset_t} one at a time.

Note that nothing prevents a user from writing a bracket expression
like this: @code{[aeiouyAEIOUYaeiouy]}, where letters are repeated.
We handle this later on, when building the final data structure.
Initially, we simply add each character into @code{set->chars}.

@<API functions@>=
/* charset_add_char --- add a single wide character to the set */

bool
charset_add_char(charset_t *set, int32_t wc, int *errcode)
{
	@<check for NULL pointers@>
	@<check if finalized@>

	@<create or grow the array of wide characters@>

	set->chars[set->nchars_inuse++] = wc;
	set->chars[set->nchars_inuse] = L'\0';	// make it into a string

	*errcode = CSET_SUCCESS;
	return true;
}
@

We check for @code{NULL} pointers in every function:

@<check for NULL pointers@>=
if (set == NULL) {
	if (errcode != NULL)
		*errcode = CSET_EBADPTR;
	return false;
}
@

We use the term @dfn{finalized} to mean that we have
already built the final data structures. This occurs
(as we'll see later) the first time the set is tested
for membership of a character.  Until that time, characters,
ranges, and other things may be added willy-nilly to
the @code{charset_t}; finalizing cleans it all up.
However, once finalized, nothing more may be added;
we check that in every API function.

@<check if finalized@>=
if (set->finalized) {
	*errcode = CSET_EFROZEN;
	return false;
}
@

The array of wide characters must be held in the @code{charset_t},
since items are added incrementally, and not all at once as
in the previous incarnation (setsearch). The code to create
or grow the array follows a standard pattern.

@<create or grow the array of wide characters@>=
if (set->chars == NULL) {
	set->chars = (int32_t *) malloc(sizeof(int32_t) * INITIAL_ALLOCATION);
	if (set->chars == NULL) {
		*errcode = CSET_ESPACE;
		return false;
	}
	set->nchars_allocated = INITIAL_ALLOCATION;
	set->nchars_inuse = 0;
} else if (set->nchars_inuse + 1 >= set->nchars_allocated) {
	int new_amount = set->nchars_allocated * 2;
	int32_t *new_data = (int32_t *) realloc(set->chars, new_amount * sizeof(int32_t));

	if (new_data == NULL) {
		*errcode = CSET_ESPACE;
		return false;
	}
	memset(new_data + set->nchars_allocated, 0, set->nchars_allocated * sizeof(int32_t));
	set->nchars_allocated = new_amount;
	set->chars = new_data;
}
@

@<macros@>=
#define INITIAL_ALLOCATION 10
@

@<API declarations@>=
bool charset_add_char(charset_t *set, int32_t wc, int *errcode);
@

@node Adding Ranges
@section Adding Ranges

As mentioned, a range looks like @code{[a-z]}.  Ranges are represented
as @code{RANGE_ITEM}s.  The left hand value must be less than or equal
to the right hand value.

Here too, a user can write something (silly) like @code{[a-eqra-ezhb-d]}
This will initially create three @code{RANGE_ITEM}s, @code{a-e}, @code{a-e} (a
second time) and @code{b-d}.  The final range is subsumed within the
first one.  Finalizing the data structure cleans all this up so that in
the end there is only one @code{RANGE_ITEM}, for @code{a-e}.

@<API functions@>=
/* charset_add_range --- add a range item */

bool
charset_add_range(charset_t *set, int32_t first, int32_t last, int *errcode)
{
	@<check for NULL pointers@>
	@<check if finalized@>

	if (first > last) {
		*errcode = CSET_ERANGE;
		return false;
	}

	@<create or grow the set of items if necessary@>

	set_item new_item;
	new_item.item_type = RANGE_ITEM;
	new_item.start = first;
	new_item.end = last;
	set->items[set->nelems++] = new_item;

	*errcode = CSET_SUCCESS;
	return true;
}
@

This code is the same as for dealing with the array of characters.

@<create or grow the set of items if necessary@>=
if (set->items == NULL) {
	set->items = (set_item *) malloc(sizeof(set_item) * INITIAL_ALLOCATION);
	if (set->items == NULL) {
		*errcode = CSET_ESPACE;
		return false;
	}
	set->allocated = INITIAL_ALLOCATION;
	set->nelems = 0;
} else if (set->nelems + 1 >= set->allocated) {
	int new_amount = set->allocated * 2;
	set_item *new_data = (set_item *) realloc(set->items, new_amount * sizeof(set_item));

	if (new_data == NULL) {
		*errcode = CSET_ESPACE;
		return false;
	}
	memset(new_data + set->allocated, 0, set->allocated * sizeof(set_item));
	set->allocated = new_amount;
	set->items = new_data;
}
@

Regular expressions use the @samp{.} (dot) metacharacter to mean
``match any character.''  This can be represented simply as a range
from zero to the maximum allowed character value. In Unicode, this
is @code{0x10ffff}, and we make the assumption that this applies to
other wide character sets as well.

@<macros@>=
#define MAX_CODE_POINT 0x10ffff	// max Unicode code point
@

There is a small wrinkle. If @code{CSET_NO_NEWLINE} is used, dot cannot
match the newline character.  That's handled simply by having two range
items, one from zero to ``newline minus one'' and the other from
``newline plus one'' to the maximum value.
Otherwise, only a single range item is needed.

@<API functions@>=
/* charset_add_all_chars --- make a range with all possible characters */

bool
charset_add_all_chars(charset_t *set, int *errcode)
{
	@<check for NULL pointers@>
	@<check if finalized@>

	if (set->no_newlines) {
		if (! charset_add_range(set, 0, L'\n' - 1, errcode))
			return false;
		if (! charset_add_range(set, L'\n' + 1, MAX_CODE_POINT, errcode))
			return false;
	} else {
		if (! charset_add_range(set, 0, MAX_CODE_POINT, errcode))
			return false;
	}

	*errcode = CSET_SUCCESS;
	return true;
}
@

@<API declarations@>=
bool charset_add_range(charset_t *set, int32_t first, int32_t last, int *errcode);
bool charset_add_all_chars(charset_t *set, int *errcode);
@

@node Inverting
@section Inverting The Charset

A bracket expression may @dfn{complemented}, meaning that it should match
any character @emph{not} in the set. For example, @code{[^aeiouyAEIOUY]}
matches any non-vowel character (for English).  This function marks the
@code{charset_t} as being complemented, or inverted.  This is a one-way
operation; it cannot be undone.

@<API functions@>=
/* charset_invert --- mark charset to return success if requested character not found */

bool charset_invert(charset_t *set, int *errcode)
{
	@<check for NULL pointers@>
	@<check if finalized@>

	set->complemented = true;
	*errcode = CSET_SUCCESS;
	return true;
}
@

@<API declarations@>=
bool charset_invert(charset_t *set, int *errcode);
@

@node The Funky Stuff
@section Character Classes, Equivalence Classes, and Collating Sequences

Besides characters and ranges, POSIX specifies three additional kinds of
items that can occur inside a bracket expression, and which we have to
be able to handle: character classes, equivalence classes, and collating
sequences.

@node Character Classes
@subsection  Character Classes

Character classes provide a locale-independent way of matching
groups of characters, such as ``alphabetic'' or ``punctuation.''
You write them like so: @code{[[:alpha:]]}. In other words,
delimited by @code{[:} and @code{:]} inside the outer brackets
of the bracket expression.

We expect the regexp parser to pull the name out of the expression
(e.g., @code{alpha}), and hand that to us as a regular C string.
The string is looked up with @code{wctype()} (see the manpage)
and the return value stored for later use with the @code{iswctype()}
function. The string is copied and stored also, for debug use.

@<API functions@>=
/* charset_add_cclass --- add a character class, like "alnum" */

bool charset_add_cclass(charset_t *set, const char *cclass, int *errcode)
{
	@<check for NULL pointers@>
	@<check if finalized@>

	@<create or grow the set of items if necessary@>

	wctype_t the_type = wctype(cclass);
	if (the_type == 0) {	// not a known class name
		*errcode = CSET_ECTYPE;
		return false;
	}

	const char *class_name = strdup(cclass);
	if (class_name == NULL) {
		*errcode = CSET_ESPACE;
		return false;
	}

	set_item new_item;
	new_item.item_type = CTYPE_ITEM;

	new_item.wtype = the_type;
	new_item.type_name = class_name;
	set->items[set->nelems++] = new_item;

	*errcode = CSET_SUCCESS;
	return true;
}
@

As with the regular character and the ranges, duplicates are
possible; that's cleaned up upon finalization.

@<API declarations@>=
bool charset_add_cclass(charset_t *set, const char *cclass, int *errcode);
@

@node Equivalence Classes
@subsection Equivalence Classes

An equivalence class describes a set of equivalent characters.
For example, in a French locale, @code{[[=e=]]} might match @code{e}, 
@code{@^e}, @code{@`e}, and @code{@'e}.

Here is Mike's portable but ``sleazy'' (sic) way to add all
the equivalent characters:

@<API functions@>=
/* charset_add_equiv --- add an equivalence class */

bool charset_add_equiv(charset_t *set, int32_t equiv, int *errcode)
{
	@<check for NULL pointers@>
	@<check if finalized@>

	wchar_t wcs_in[2];
	wchar_t wcs[2];
	wchar_t abuf[100], wbuf[100];

	wcs_in[0] = equiv;
	wcs_in[1] = 0;
	wcsxfrm(abuf, wcs_in, 99);
	wcs[1] = 0;
	for (wchar_t u = 1; u <= MAX_CODE_POINT; ++u) {
		wcs[0] = u;
		wcsxfrm(wbuf, wcs, 99);
		if (abuf[0] == wbuf[0])
			if (! charset_add_char(set, u, errcode))
				return false;
	}

	*errcode = CSET_SUCCESS;
	return true;
}
@

@<API declarations@>=
bool charset_add_equiv(charset_t *set, int32_t equiv, int *errcode);
@

@node Collating Sequences
@subsection  Collating Sequences

A collating sequence is a group of characters that should be
treated as if it were a single character. It might be written
like @code{[[.oa.]]}.  We support collating sequences of length one.

@<API functions@>=
/* charset_add_collate --- add a collating sequence */

bool charset_add_collate(charset_t *set, const int32_t *collate, int *errcode)
{
	@<check for NULL pointers@>
	@<check if finalized@>

	// only single character collating sequences allowed,
	// at least right now
	if (collate[1] != L'\0') {
		*errcode = CSET_ECOLLATE;
		return false;
	}

	return charset_add_char(set, collate[0], errcode);
}
@

@<API declarations@>=
bool charset_add_collate(charset_t *set, const int32_t *collate, int *errcode);
@

@node The Easy Stuff
@chapter Using The @code{charset_t} Once It's Built

A fundamental assumption is that the array of items
is sorted and uniqued. In addition, all @code{CTYPE_ITEM}s
are at the front of the array, so that they can be tested
first.

The following function tests if a character is contained
in the @code{charset_t}.

@<API functions@>=
/* charset_in_set --- see if a character is in the set */

bool
charset_in_set(const charset_t *set, int32_t the_char, int *errcode)
{
	@<check for NULL pointers@>
	*errcode = CSET_SUCCESS;

	if (! set->finalized) {
		finalize((charset_t *) set, errcode);

		if (*errcode != CSET_SUCCESS)	// finalize() failed
			return false;
	}

	if (the_char == L'\n' && set->no_newlines && set->complemented)
		return false;

	bool found = is_found(set, the_char);
	if (set->complemented)
		found = ! found;		// reverse sense of the match

	return found;
}
@

When we're done with the @code{charset_t}, we should
release all the storage it uses.

@<API functions@>=
/* charset_free --- free all storage */

bool
charset_free(const charset_t *set, int *errcode)
{
	@<check for NULL pointers@>
	// no need to check for finalized

	for (int i = 0; i < set->nelems; i++) {
		if (set->items[i].item_type == CTYPE_ITEM)
			free((void *) set->items[i].type_name);
		else
			break;
	}

	if (set->chars != NULL)
		free((void *) set->chars);

	free((void *) set->items);
	free((void *) set);

	*errcode = CSET_SUCCESS;
	return true;
}
@

@<API declarations@>=
bool charset_in_set(const charset_t *set, int32_t the_char, int *errcode);
bool charset_free(const charset_t *set, int *errcode);
@

@node Searching
@section Searching For A Character

The actual searching is separate from the ``is complemented'' test to
keep things simple.

@<helper functions@>=
@<item comparison functions@>

/* is_found --- return true if the character is found */

static bool
is_found(const charset_t *set, int32_t the_char)
{
	set_item *items = set->items;
	int i;

	@<Special case search for only one item in the set@>
	@<Search for a @code{CTYPE_ITEM}@>
	@<Search for a @code{RANGE_ITEM}@>
}
@

The @code{CTYPE_ITEM}s are checked before the @code{RANGE_ITEM}s, since
each one can match multiple characters with a single function call:

@<Search for a @code{CTYPE_ITEM}@>=
for (i = 0; i < set->nelems; i++) {
	// linear search of ctype items
	if (items[i].item_type == RANGE_ITEM)
		break;

	assert(items[i].item_type == CTYPE_ITEM);
	if (iswctype(the_char, items[i].wtype))
		return true;
}

if (i >= set->nelems)
	return false;
@

Searching for a matching @code{RANGE_ITEM} is
done using binary search:

@<Search for a @code{RANGE_ITEM}@>=
assert(items[i].item_type == RANGE_ITEM);

// binary search to see if we have it
set_item *found;
set_item key;
key.item_type = RANGE_ITEM;
key.start = key.end = the_char;

found = bsearch(& key, set->items + i, set->nelems - i,
				sizeof(set_item), item_compare_for_searching);

return found != NULL;
@

We need the header file for assertions:

@<includes@>=
#include <assert.h>
@

As a special case, if the set has only one character
in it, we avoid the overhead of binary search:

@<Special case search for only one item in the set@>=
if (set->nelems == 1 && set->items[0].item_type == RANGE_ITEM) {
    return (set->items[0].start <= the_char && the_char <= set->items[0].end);
}
@

We need two comparison functions: one for use by @code{bsearch()} and
a different one for use by by @code{qsort()} (which we'll see later).
The comparisons are fundamentally different. When sorting,
we're comparing array elements against each other. When
searching, we compare elements one at a time against a key.
The sorting comparison is more elaborate:

Here is the searching function.  POSIX tells us that the first
argument is the key and the second is the array element being
compared.

@<item comparison functions@>=
/* item_compare_for_searching --- compare two set_items */

static int
item_compare_for_searching(const void *k, const void *e)
{
	set_item *thekey = (set_item *) k;
	set_item *elem = (set_item *) e;

	assert(thekey->item_type == RANGE_ITEM && elem->item_type == RANGE_ITEM);

	if (elem->start <= thekey->start && thekey->start <= elem->end)
		return 0;	// found it
	else if (thekey->end < elem->start)
		return -1;
	else {
		assert(thekey->start > elem->end);
		return 1;
	}
}
@

@node Printing
@section Printing The Data Structure

Printing the data is straightforward.

@<API functions@>=
/* charset_dump --- dump out the data structures */

void
charset_dump(const charset_t *set, FILE *fp)
{
	static const char *boolval[] = {
		"false",
		"true",
	};

	if (set == NULL || fp == NULL)
		return;

	fprintf(fp, "complemented = %s\n", boolval[!! set->complemented]);
	fprintf(fp, "no_newlines = %s\n", boolval[!! set->no_newlines]);
	fprintf(fp, "finalized = %s\n", boolval[!! set->finalized]);

	set_item *items = set->items;
	for (int i = 0; i < set->nelems; i++) {
		if (items[i].item_type == CTYPE_ITEM) {
			fprintf(fp, "%3d. CTYPE: [:%s:]\n", i, items[i].type_name);
			continue;
		}
		assert(items[i].item_type == RANGE_ITEM);
		fprintf(fp, "%3d. RANGE: start = L'%lc', end = L'%lc'\n",
			i, items[i].start, items[i].end);
	}
	fflush(fp);
}
@

@<API declarations@>=
void charset_dump(const charset_t *set, FILE *fp);
@

@node Finalizing
@chapter Finalizing The Charset

Now it's time to do the hard part, which is to produce the
final data structure.

@<helper functions@>=
/* finalize --- condense all the info into the final data structure */

static void
finalize(charset_t *set, int *errcode)
{
	assert(set != NULL && errcode != NULL);

	@<sort wide character list@>
	@<condense wide character list into @code{RANGE_ITEM}s@>
	@<condense final array of @code{set_item}s@>
	set->finalized = true;
}
@

Once we have the list of wide characters, sorting it is easy:

@<sort wide character list@>=
qsort(set->chars, set->nchars_inuse, sizeof(wint_t), wint_compare);
@

@noindent
The comparison function is trivial:

@<item comparison functions@>=
/* wint_compare --- compare two wint values for qsort */

static int
wint_compare(const void *l, const void *r)
{
	wint_t *left = (wint_t *) l;
	wint_t *right = (wint_t *) r;

	return *left - *right;
}
@

Now some of the fun begins:

@<condense wide character list into @code{RANGE_ITEM}s@>=
@<remove duplicate wide characters@>
@<generate @code{RANGE_ITEM}s@>
@

Condensing the list simply shifts the characters down
as duplicates are found.  This is painful if there are
maybe thousands of duplicates but for typical regular
expressions, there shouldn't be any problem.

@<remove duplicate wide characters@>=
size_t i, j;
for (i = 0, j = 1; j < set->nchars_inuse; i++, j++) {
	if (set->chars[i] == set->chars[j]) {
		for (int k = j + 1; k < set->nchars_inuse; j++, k++) {
			set->chars[j] = set->chars[k];
		}
		set->chars[j] = L'\0';

		set->nchars_inuse--;
		j = i;
		i--;	// keep searching from same spot
	}
}
if (set->chars != NULL)
	set->chars[set->nchars_inuse] = L'\0';	// not strictly necessary, but doesn't hurt
@

Once we have a sorted and uniqued list of wide characters,
generating the correct ranges is relatively easy.

@<generate @code{RANGE_ITEM}s@>=
size_t range_start, total;
range_start = total = 0;
for (i = 0, j = 1; j < set->nchars_inuse; i++, j++) {
	if (set->chars[j] == set->chars[i] + 1) {	// ab...
		continue;
	} else if (set->chars[j] > set->chars[i] + 1) {
		// acd...
		// push a and start next range at c
		if (! charset_add_range(set, 
				set->chars[range_start], set->chars[i], errcode))
			return;
		total++;
		range_start = j;
	}
}
// Get any final range or character
if (set->nchars_inuse > 0 && range_start <= set->nchars_inuse - 1) {
	if (! charset_add_range(set, set->chars[range_start],
				set->chars[set->nchars_inuse-1], errcode))
			return;
	total++;
}
set->nchars_inuse = total;
@

@<condense final array of @code{set_item}s@>=
// sort it
qsort(set->items, set->nelems,
		sizeof(set_item), item_compare_for_sorting);

// condense it
set_item *items = set->items;
for (i = 0, j = 1; j < set->nelems; i++, j++) {
	if (   items[i].item_type == CTYPE_ITEM
		&& items[j].item_type == CTYPE_ITEM
		&& items[i].wtype == items[j].wtype) {
		free((void *) items[j].type_name);
		@<shift @code{items} down by one@>
	} else if (items[i].item_type != items[j].item_type) {
		continue;
	} else if (items[i].item_type == RANGE_ITEM) {
		@<condense overlapping ranges@>
	}
}
@

We want @code{CTYPE_ITEM}s to sort to the front of the list.  For sorting,
we sort the @code{RANGE_ITEM}s based on their @code{start} value.
For searching, we have to compare with the value in @code{key},
and we will only be looking at @code{RANGE_ITEM}s.
Here's the sorting function:

@<item comparison functions@>=
/* item_compare_for_sorting --- compare two set_items */

static int
item_compare_for_sorting(const void *l, const void *r)
{
	set_item *left = (set_item *) l;
	set_item *right = (set_item *) r;

	if (left->item_type == CTYPE_ITEM && right->item_type == CTYPE_ITEM) {
		return left->wtype - right->wtype;
	} else if (left->item_type == CTYPE_ITEM && right->item_type == RANGE_ITEM) {
		return -1;
	} else if (left->item_type == RANGE_ITEM && right->item_type == CTYPE_ITEM) {
		return +1;
	} else {
		assert(left->item_type == RANGE_ITEM && right->item_type == RANGE_ITEM);
		return left->start - right->start;
	}
}
@

There are multiple possibilities for
overlapping ranges. For example, there's nothing stopping
someone from writing @code{[a-q12c-h]}, or @code{[bca123a-c]} or
almost anything else.  After sorting the various ranges, we
end up with the following possibilities:

@itemize @bullet
@item
Exact duplicate ranges:

@example
          +---+---+
item[i]   | a | d |        +---+---+
          +---+---+   ==>  | a | d |   item[i]
item[j]   | a | d |        +---+---+
          +---+---+
@end example

@noindent
The duplicate should be removed.

@item
Adjacent ranges.

@example
          +---+---+
item[i]   | a | d |                +---+---+
          +---+---+---+----   ==>  | a | h |   item[i]
item[j]           | e | h |        +---+---+
                  +---+---+
@end example

@noindent
The first range should be expanded to include the
end point of the second, and the second one should
be removed.

@item
Completely overlapping:

@example
          +----------+
item[i]   | abcdefhi |          +---+---+
          +----------+    ===>  | a | i |   item[i]
item[j]   |    def   |          +---+---+
          +----------+
@end example

@noindent
The second one should be removed.

@item
Partially overlapping on the left:

@example
          +----------+
item[i]   | abcdef   |         +---+---+
          +----------+    ===> | a | h |   item[i]
item[i]   |    defgh |         +---+---+
          +----------+
@end example

@noindent
Since ranges are sorted by @code{start}, we won't
have overlapping on the right.
Here too, the end point of the first range
should become that of the second, and
the second should be removed.
@end itemize

The following sequence of statements implements the logic:

@<condense overlapping ranges@>=
bool need_shift = false;
if (items[i].start == items[j].start && items[i].end == items[j].end) {
	need_shift = true;
} else if (items[i].end + 1 == items[j].start) {
	items[i].end = items[j].end;
	need_shift = true;
} else if (items[i].start < items[j].start && items[i].end > items[j].end) {
	need_shift = true;
} else if (   items[i].start <= items[j].start
           && items[i].end > items[j].start
           && items[j].end >= items[i].end) {
	items[i].end = items[j].end;
	need_shift = true;
}
if (need_shift) {
	@<shift @code{items} down by one@>
}
// otherwise, just continue around the loop
@

@<shift @code{items} down by one@>=
for (int k = j + 1; k < set->nelems; j++, k++)
	items[j] = items[k];

set->nelems--;
i--;	// compensate for loop, continue checking at current position
j = i + 1;
@

@node Source Files
@chapter Source Files

@(charset.h@)=
#ifndef CHARSET_H
#define CHARSET_H 1

@<Copyright statement@>

#include <stdio.h>
#include <stdbool.h>
#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

typedef struct _charset charset_t;

@<API declarations@>

#ifdef __cplusplus
}
#endif
#endif /* CHARSET_H */
@

@(charset.c@)=
@<Copyright statement@>

@<includes@>
#include "charset.h"	// for the charset_t typedef

@<macros@>

@<data structures@>
@<helper functions@>
@<API functions@>
@

To get it out of the way, here is the copyright statement.

@<Copyright statement@>=
// Copyright (C) 2024, Arnold David Robbins.
// All rights reserved.  Not for redistribution (yet...).
@

We include the standard header files that we'll need:

@<includes@>=
#include <stdio.h>
#include <stdbool.h>
#include <stddef.h>
#include <stdint.h>
#include <stdlib.h>
#include <string.h>
#include <wctype.h>
#include <wchar.h>
#include <locale.h>
@

@node test driver
@chapter A Test Program And Driver

We need a test program, and a shell script to drive it:

@node test program
@section The Test Program

The test program builds a set and then compares one or more characters
against the set.  It takes several options:

@table @option
@item -F
Expect failure. Mutually exclusive with @option{-S}.

@item -S
Expect success. Mutually exclusive with @option{-F}.

@item -D
Match ``dot'' (any character).

@item -d
Dump the data structure.

@item -e
Escapes are allowed (like @command{awk}). By default they are not.

@item -i
Ignore case when matching. By default case is significant.

@item -n
Disallow newlines when matching dot or complemented bracket
expressions.

@item -q
Be quiet: don't print out what we're attempting match.
@end table

@strong{FIXME:} Make sure the above is complete.

@(btest.c@)=
/* btest.c --- a test program for the charset_xxx functions */

@<Copyright statement@>

@<main includes@>

static charset_t *parse_bracket_expr(const char *expr, int flags, int *errcode);
static const char *errcode2string(int errcode);
		
enum flags {
	SS_ESCAPES_ALLOWED	= 0x01,
	SS_IGNORE_CASE		= 0x02,
	SS_NO_NEWLINES		= 0x04,
	SS_DOT			= 0x08,
};

static bool
find_ctype_info(const char *cp,
                const char **the_name, int *errcode,
                size_t mb_cur_max, mbstate_t *mbsp);
@<test helper functions@>

/* main --- parse arguments, run the test */

int
main(int argc, char **argv)
{
	int c;
	wint_t wc;
	char *cp;
	bool expect_success = false, expect_failure = false;
	bool dump_data = false, quiet = false;

	@<parse command line arguments@>
	setlocale(LC_ALL, "");
	@<compile the expression@>
	@<test each wide character in the test case against the expression@>
	@<dump the data if needed@>

	return EXIT_SUCCESS;
}
@

@<main includes@>=
@<includes@>
#include <getopt.h>
#include "charset.h"
@

@<parse command line arguments@>=
int flags = 0;
while ((c = getopt(argc, argv, "SFdDeinq")) != -1) {
	switch (c) {
	case 'S':
		expect_success = true;
		break;
	case 'F':
		expect_failure = true;
		break;
	case 'd':
		dump_data = true;
		break;
	case 'D':
		flags |= SS_DOT;
		break;
	case 'e':
		flags |= SS_ESCAPES_ALLOWED;
		break;
	case 'i':
		flags |= SS_IGNORE_CASE;
		break;
	case 'n':
		flags |= SS_NO_NEWLINES;
		break;
	case 'q':
		quiet = true;
		break;
	case '?':
		usage(argv[0]);
		break;
	}
}

if (   (! expect_success && ! expect_failure)
    || (expect_success && expect_failure)) {
	fprintf(stderr, "You must give exactly one of -S or -F.\n");
	usage(argv[0]);
}
else if (optind + 2 > argc)	// no expr or no string provided
	usage(argv[0]);
@

@<test helper functions@>=
@<usage function@>
@

@<usage function@>=
/* usage --- print a usage message and die */

static void
usage(const char *name)
{
	fprintf(stderr, "Usage: %s -S|-F [-deiq] '[bracket-expression]'" \
					" '<string of characters>'\n",
			name);
	fprintf(stderr, "\t-S\tExpect match success.\n");
	fprintf(stderr, "\t-F\tExpect failure of some kind.\n");
	fprintf(stderr, "\t-d\tDump the data structure.\n");
	fprintf(stderr, "\t-D\tMatch \"dot\" (any character).\n");
	fprintf(stderr, "\t-e\tEscapes are allowed.\n");
	fprintf(stderr, "\t-i\tIgnore case.\n");
	fprintf(stderr, "\t-n\tNo newlines in [^...] or \"dot\".\n");
	fprintf(stderr, "\t-q\tRun quietly.\n");
	exit(EXIT_FAILURE);
}
@

@<compile the expression@>=
charset_t *bracket_expr;
int errcode = 0;

bracket_expr = parse_bracket_expr(argv[optind], flags, & errcode);
if (bracket_expr == NULL && expect_success) {
	fprintf(stderr, "bad expression: %s\n", errcode2string(errcode));
	// can't dump the data, return was NULL
	exit(EXIT_FAILURE);
}
@

@<test each wide character in the test case against the expression@>=
mbstate_t mbs;
memset(& mbs, 0, sizeof(mbs));
if (! quiet)
	printf("expect %s: %s: %s\n", expect_success ? "success" : "failure",
			argv[optind], argv[optind+1]);

int mb_cur_max = MB_CUR_MAX;
for (cp = argv[optind + 1]; *cp != '\0';) {
	size_t count;

	count = mbrtowc(& wc, cp, mb_cur_max, & mbs);
	if (count == (size_t) -1 || count == (size_t) -2) {
		count = 1;
		wc = *cp & 0xFF;
		cp++;	// skip over it and hope;
		memset(& mbs, 0, sizeof(mbs));	// reset the state
	} else
		cp += count;

	bool matched = charset_in_set(bracket_expr, wc, & errcode);
	if (! matched && expect_success) {
		fprintf(stderr, "%s: failed to match L'%lc', success expected.\n", argv[optind], wc);
		@<dump the data if needed@>
		exit(EXIT_FAILURE);
	} else if (matched && expect_failure) {
		fprintf(stderr, "%s: succeeded to match L'%lc', failure expected.\n", argv[optind], wc);
		@<dump the data if needed@>
		exit(EXIT_FAILURE);
	}
}
@

@<dump the data if needed@>=
if (dump_data) {
	printf("escapes_allowed = %s\n",
			(flags & SS_ESCAPES_ALLOWED) != 0 ? "true" : "false");
	printf("ignore_case = %s\n",
			(flags & SS_IGNORE_CASE) != 0 ? "true" : "false");
	charset_dump(bracket_expr, stdout);
}
@

@<test helper functions@>=
/* errcode2string --- turn a charset error code into a string */

static const char *
errcode2string(int errcode)
{
	static char buf[100];
	static const char *messages[] = {
		"success",					// CSET_SUCCESS
		"bad pointer",				// CSET_EBADPTR
		"frozen set",				// CSET_EFROZEN
		"bad collation sequence",	// CSET_ECOLLATE
		"bad character class",		// CSET_ECTYPE
		"no memory",				// CSET_ESPACE
		"bad range",				// CSET_ERANGE
	};

	if (errcode < CSET_SUCCESS || errcode > CSET_ERANGE) {
		sprintf(buf, "unknown error code: %d", errcode);
		return buf;
	}

	return messages[errcode];
}
@

@node parsing the expression
@section Parsing The Bracket Expression

So, it seems that the hairiest part of setsearch was actually
the code to parse the bracket expression and build up the data
structure as it went along.  For the refactoring into this API,
that code isn't needed.  However, it turns out that it is
extremely useful for the test program!  So, we'll reuse it
here.  Be prepared, it's a big chunk of code.

@<test helper functions@>=
/* parse_bracket_expr --- convert a bracket expression into a charset_t */

static charset_t *
parse_bracket_expr(const char *expr, int flags, int *errcode)
{
	@<variables for parsing@>
	@<init variables for parsing@>
	bool ignore_case = (flags & SS_IGNORE_CASE) != 0;
	bool escapes_allowed = (flags & SS_ESCAPES_ALLOWED) != 0;
	bool no_newlines = (flags & SS_NO_NEWLINES) != 0;
	bool do_dot = (flags & SS_DOT) != 0;

	if (expr == NULL) {
		if (errcode != NULL)
			*errcode = CSET_EBADPTR;
		return NULL;
	}

	charset_t *bracket_expr = charset_create(no_newlines ? CSET_NO_FLAGS : CSET_NO_FLAGS, errcode);
	if (bracket_expr == NULL)
		return NULL;

	@<get a wide character@>
	if (a_wchar == L'.' && do_dot) {
		if (! charset_add_all_chars(bracket_expr, errcode))
			goto fail;
		return bracket_expr;
	}

	if (a_wchar != L'[') {
		*errcode = CSET_ERANGE;	// not really right
		return NULL;
	}

	// main loop:
	while (cp < last) {
		@<get current wide character@>
		if (at_first_char && cur_wchar == L'^') {
			if (! charset_invert(bracket_expr, errcode))
				goto fail;

			// get the next character and then fall through
			@<get current wide character@>
		}

		if (! at_first_char && ! escaped && cur_wchar == L']')
			break;		// all done

		at_first_char = false;

		if (escaped)
			goto check_for_range;

		if (cur_wchar == L'[') {
			@<peek at next wide character@>
			if (wcschr(L":=.", next_wchar) == NULL)
				goto check_for_range_2;

			@<get current wide character@>
			@<process @code{[:...:]} items@>
			@<process @code{[=...=]} items@>
			@<process @code{[.X.]} items@>
		}

	check_for_range:

		@<peek at next wide character@>

	check_for_range_2:
		first_range_char_invalid = invalid;

		if (next_wchar == L'-') {
			wint_t first_wc, second_wc;

			first_wc = cur_wchar;
			// consume the '-'
			cp += n;

			// and get the second character
			@<peek at next wide character@>

			if (first_range_char_invalid || invalid /* 2nd range char */) {
				*errcode = CSET_ERANGE;
				goto fail;
			}

			if (next_wchar == L']') {
				// '-' was before terminating ']', treat literally
				if (! charset_add_char(bracket_expr, first_wc, errcode))
					goto fail;
				cur_wchar = L'-';
				goto push_wchar;
			} else {
				@<get current wide character@>
			}

			second_wc = cur_wchar;
			if (second_wc < first_wc) {
				*errcode = CSET_ERANGE;
				goto fail;
			}
			if (! charset_add_range(bracket_expr, first_wc, second_wc, errcode))
				goto fail;
			if (ignore_case) {
				bool result;

				if (iswlower(first_wc) && iswlower(second_wc))
					result = charset_add_range(bracket_expr, towupper(first_wc),
									towupper(second_wc), errcode);
				else if (iswupper(first_wc) && iswupper(second_wc))
					result = charset_add_range(bracket_expr, towlower(first_wc),
									towlower(second_wc), errcode);
				if (! result)
					goto fail;
			}

			continue;
		}

	push_wchar:
		// push cur_wchar onto wide character list
		if (! charset_add_char(bracket_expr, cur_wchar, errcode))
			goto fail;
		if (ignore_case) {
			bool result;

			if (iswlower(cur_wchar))
				result = charset_add_char(bracket_expr, towupper(cur_wchar), errcode);
			else if (iswupper(cur_wchar))
				result = charset_add_char(bracket_expr, towlower(cur_wchar), errcode);

			if (! result)
				goto fail;
		}
	}

	if (cur_wchar != L']') {
		*errcode = CSET_ERANGE;	// not perfect
		goto fail;
	}

	return bracket_expr;

fail:
	charset_free(bracket_expr, errcode);
	return NULL;
}
@

Here are the variables we need when working through
the expression using wide characters.

@<variables for parsing@>=
wint_t a_wchar, cur_wchar, next_wchar;
size_t n;
const char *cp, *last;
bool at_first_char = true;
bool escaped = false;
bool invalid = false;
bool first_range_char_invalid = false;
mbstate_t mbs;
size_t mb_cur_max = MB_CUR_MAX;
@

Initialization is obvious:

@<init variables for parsing@>=
cp = expr;
last = expr + strlen(expr);
memset(& mbs, 0, sizeof(mbs));
@

We need to get the current wide character and
advance @code{cp}. In so doing, we have to handle
escaped characters as well:

@<get current wide character@>=
@<get a wide character@>
if (escapes_allowed && a_wchar == L'\\') {
	@<get a wide character@>
	cur_wchar = a_wchar;
	at_first_char = false;
	escaped = true;
} else {
	escaped = false;
	cur_wchar = a_wchar;
}
@

This actually gets the next wide character:

@<get a wide character@>=
n = mbrtowc(& a_wchar, cp, mb_cur_max, & mbs);
if (n == (size_t) -1 || n == (size_t) -2) {
	// treat bad bytes as individual code points,
	// even if invalid and just skip over them.
	a_wchar = *cp & 0xFF;
	if (mb_cur_max > 1)
		invalid = true;
	n = 1;
	// after an invalid conversion, reinitialize mbsmbsp
	memset(& mbs, 0, sizeof(mbs));
}
cp += n;
@

And we also need to be able to peek ahead:

@<peek at next wide character@>=
n = mbrtowc(& next_wchar, cp, mb_cur_max, & mbs);
if (n == (size_t) -1 || n == (size_t) -2) {
	// here too, treat bad bytes as individual code points,
	// even if invalid and just skip over them.
	a_wchar = *cp & 0xFF;
	if (mb_cur_max > 1)
		invalid = true;
	n = 1;
	// after an invalid conversion, reinitialize mbs
	memset(& mbs, 0, sizeof(mbs));
}
// since we are peeking, we do NOT advance cp
@

@node ctype items
@subsection Handling Character Classes Like @code{[:alpha:]}

Now, it's time to deal with @code{[...[:alpha:]...]}.
POSIX allows for locales to have additional character classes
above and beyond the standard 12 classes available in every locale.
This means we have to ``nerd through'' the string to find the name,
copy it, and then look it up with with @code{wctype()}.  Sigh.

Even worse, since we're working with wide characters, we'll
have to convert what we find back to a multibyte string
before calling @code{wctype()}.

@<process @code{[:...:]} items@>=
if (cur_wchar == L':') {
	const char *the_name = NULL;

	if (! find_ctype_info(cp, & the_name,
			errcode, mb_cur_max, & mbs)) {
		if (the_name != NULL)
			free((void *) the_name);
		goto fail;
	}

	cp += strlen(the_name) + 2;	// +2 for closing :]
	if (! charset_add_cclass(bracket_expr, the_name, errcode)) {
		if (the_name != NULL)
			free((void *) the_name);
		goto fail;
	}
	free((void *) the_name);	// it's copied inside charset_add_cclass

	continue;
}
@

@<test helper functions@>=
/* find_ctype_info --- fill in the info for a character class */

static bool
find_ctype_info(const char *cp,
                const char **the_name, int *errcode,
                size_t mb_cur_max, mbstate_t *mbsp)
{
	const char *begin = cp;
	size_t len = strlen(cp);
	const char *last = cp + len;
	char *name_buf;
	wchar_t *w_name_buf;
	wchar_t *namep = NULL;
	wint_t a_wchar;
	size_t n;
	bool invalid = false;
// This is a hack, but it's "just" test code
#define mbs	(*mbsp)

	w_name_buf = (wchar_t *) malloc((len + 1) * sizeof(wchar_t));
	if (w_name_buf == NULL) {
		*errcode = CSET_ESPACE;
		return false;
	}
	memset(w_name_buf, 0, (len + 1) * sizeof(wchar_t));

	for (namep = w_name_buf; cp < last;) {
		@<get a wide character@>
		if (a_wchar == L':') {
			break;
		}
		*namep++ = a_wchar;
	}

	*namep = L'\0';
	@<get a wide character@>
	if (a_wchar != L']') {
		*errcode = CSET_ECTYPE;
		free(w_name_buf);
		return false;
	}

	name_buf = (char *) malloc(len + 1);
	if (name_buf == NULL) {
		*errcode = CSET_ESPACE;
		free(w_name_buf);
		return false;
	}
	memset(name_buf, 0, len + 1);

	mbstate_t mbs2;	// use a separate mbstate_t
	memset(& mbs2, 0, sizeof(mbs2));
	const wchar_t *name_start = w_name_buf;
	wcsrtombs(name_buf, & name_start, len + 1, & mbs2);

	*the_name = name_buf;
	free(w_name_buf);

	*errcode = CSET_SUCCESS;

	return true;
#undef mbs
}
@
@node Equivalence Classes and Collating Elements
@subsection Handling Equivalence Classes and Collating Elements

The first step for an equivalence class is to extract
the wide character and make sure it has the closing @samp{=]}.

@<process @code{[=...=]} items@>=
if (cur_wchar == L'=') {
	wint_t the_wc;
	const char *begin = cp;

	@<get current wide character@>
	the_wc = cur_wchar;

	@<peek at next wide character@>
	if (next_wchar != L'=') {
		*errcode = CSET_ECTYPE;	// not really right
		goto fail;
	}
	// consume the '='
	cp += n;
	@<peek at next wide character@>
	if (next_wchar != L']') {
		*errcode = CSET_ECTYPE;	// not really right
		goto fail;
	}
	// consume the ']'
	cp += n;

	if (! charset_add_equiv(bracket_expr, the_wc, errcode))
		goto fail;
	if (ignore_case) {
		bool result;

		if (iswlower(the_wc))
			result = charset_add_equiv(bracket_expr, towupper(the_wc), errcode);
		else if (iswupper(the_wc))
			result = charset_add_equiv(bracket_expr, towlower(the_wc), errcode);

		if (! result)
			goto fail;
	}

	continue;
}
@

We allow single character collating elements:

@<process @code{[.X.]} items@>=
if (cur_wchar == L'.') {
	wint_t the_wc;
	const char *begin = cp;

	@<get current wide character@>
	the_wc = cur_wchar;

	@<peek at next wide character@>
	if (next_wchar != L'.') {
		*errcode = CSET_ECOLLATE;
		goto fail;
	}
	// consume the '.'
	cp += n;
	@<peek at next wide character@>
	if (next_wchar != L']') {
		*errcode = CSET_ECOLLATE;
		goto fail;
	}
	// consume the ']'
	cp += n;

	if (! charset_add_char(bracket_expr, the_wc, errcode))
		goto fail;
	if (ignore_case) {
		bool result;

		if (iswlower(the_wc))
			result = charset_add_char(bracket_expr, towupper(the_wc), errcode);
		else if (iswupper(the_wc))
			result = charset_add_char(bracket_expr, towlower(the_wc), errcode);

		if (! result)
			goto fail;
	}

	continue;
}
@

@node test driver
@section The Test Program Driver Script

The idea is to have a text file containing tests, and a shell
script to read the tests and call @command{btest} appropriately.
The text file will have three columns separated by tabs:

@enumerate
@item
The command line options. At the very least one of @option{-F} or @option{-S}.

@item
The bracket expression.

@item
One or more characters to test against the bracket expression.
@end enumerate

Lines that start with @samp{#} are comment lines and are ignored, as are
empty lines.
We rely on Bash's special @code{$'@dots{}'} string notation to include TAB
characters instead of using physical TAB characters in the file.

@(runtests.sh@)=
#! /bin/bash

TESTFILE=${1:-testdata.txt}

sed -e $'/^[ \t]*#/d' -e $'/^[ \t]*$/d' $TESTFILE |
	while IFS=$'\t' read options expr chars
	do
		./btest $options "$expr" "$chars"
		echo
	done
@
@post_create runtests.sh chmod +x runtests.sh

We rely on the @file{Makefile} to save the results and compare them
to known good results.

For now, the test data is not included in this document.

@node Commentary
@chapter Commentary

@itemize @bullet
@item
The idea for the data structure was undoubtedly inspired by Russ Cox's
@uref{https://github.com/google/re2, @code{libre2}}, which uses a balanced
binary tree of ranges for handling bracket expressions.

In terms of searching, I expect the two data structures have the same
``big O'' complexity; my data structure saves the additional space overhead
of left and right subtree pointers.  Inserting into a balanced binary
tree is more complicated than my method of building the structure and then
sorting and uniquing it; however the binary tree won't insert something
that is already there.

In practice, I think it doesn't matter, as (a) most bracket expressions
are very simple and not pathological, and (b) when processing lots of
data, the amount of time spent building the data structure (compiling
the regular expression) gets lost down in the noise compared to the
amount of time spent executing it.

@item
One thing I've noticed a lot about Literate Programming is that
inlined chunks end up being used when more conventional programming
would dictate the use of a function (in C or @command{awk}) or
a macro (in C).  In particular, I sometimes miss the ability
to parameterize the objects a code chunk operates upon.

It then becomes a question: once the code is complete, should I
go back and modify things to use macros or functions? I think it
depends upon if the generated code will be what's maintained
going forward, or if the literate code will remain the main ``source''.
Thus, at least for now, the question remains open.

@item
The exercise of reworking existing code under a new API (from setsearch to charset)
has been interesting. I think the Literate Programming style has helped a lot.
I was able to copy/paste both code and prose into their places, adjusting the
code as needed, with very little trouble. In particular, the amount of reuse
is quite high, which is very pleasing.

@item
I wrote the @file{charset.3} manpage first. (It can be found in
the Github repository.) It went through several iterations before I was
happy with it. Doing so was a good idea; it helped me clarify and
simplify the API, and thus the implementation as well.

@item
I remain pleased with the underlying data structure. It is unchanged
from setsearch, as is the way it's built.
@end itemize


@node Code Chunk Summaries
@appendix Code Chunk Summaries

This @value{APPENDIX} presents alphabetical lists of
all the file definitions, the code chunk definitions,
and the code chunk references.

@menu
* File Definitions::          Source files by definition.
* Code Chunk Definitions::    Code chunks by definition.
* Code Chunk References::     Code chunks by reference.
@end menu

@node File Definitions
@appendixsec Source File Definitions

@print_file_defs

@node Code Chunk Definitions
@appendixsec Code Chunk Definitions

@print_code_defs

@node Code Chunk References
@appendixsec Code Chunk References

@print_code_refs

@node Bibliography
@unnumbered Bibliography

@node Concept Index
@unnumbered Index

@printindex cp

@bye

TODO:
